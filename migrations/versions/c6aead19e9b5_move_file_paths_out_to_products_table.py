"""move file paths out to products table

Revision ID: c6aead19e9b5
Revises: 7a2b8a59ae4f
Create Date: 2019-07-06 15:22:42.324050

"""
from alembic import op
import sqlalchemy as sa

import enum
import json
import goesbrowse.application


# revision identifiers, used by Alembic.
revision = 'c6aead19e9b5'
down_revision = '7a2b8a59ae4f'
branch_labels = None
depends_on = None

filetable = sa.Table(
    'file',
    sa.MetaData(),
    sa.Column('id', sa.Integer, primary_key=True),
    sa.Column('json', sa.JSON),
    sa.Column('jsonpath', sa.Text),
    sa.Column('datapath', sa.Text),
    sa.Column('size', sa.Integer),
)

producttable = sa.Table(
    'product',
    sa.MetaData(),
    sa.Column('id', sa.Integer, primary_key=True),
    sa.Column('path', sa.Text),
    sa.Column('size', sa.Text),
    sa.Column('type', sa.Enum('MAIN', 'META', 'THUMBNAIL', 'TIMELAPSE', name='producttype')),
    sa.Column('file_id', sa.Integer),
)

def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('product',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('path', sa.Text(), nullable=True),
    sa.Column('size', sa.Integer(), nullable=True),
    sa.Column('type', sa.Enum('MAIN', 'META', 'THUMBNAIL', 'TIMELAPSE', name='producttype'), nullable=True),
    sa.Column('file_id', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['file_id'], ['file.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('product', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_product_path'), ['path'], unique=True)
        batch_op.create_index(batch_op.f('ix_product_size'), ['size'], unique=False)
        batch_op.create_index(batch_op.f('ix_product_type'), ['type'], unique=False)

    # data migration
    connection = op.get_bind()
    appdb = goesbrowse.application.get_db()
    for file in connection.execute(filetable.select()):
        main = dict(
            path=file.datapath,
            size=file.size,
            type='MAIN',
            file_id=file.id,
        )
        try:
            metasize = (appdb.root / file.jsonpath).stat().st_size
        except Exception:
            metasize = len(json.dumps(file.json))
        meta = dict(
            path=file.jsonpath,
            size=metasize,
            type='META',
            file_id=file.id,
        )

        connection.execute(producttable.insert().values(**main))
        connection.execute(producttable.insert().values(**meta))

    with op.batch_alter_table('file', schema=None) as batch_op:
        batch_op.alter_column('json', nullable=True, existing_type=sa.JSON(), new_column_name='meta')
        batch_op.drop_index('ix_file_datapath')
        batch_op.drop_index('ix_file_jsonpath')
        batch_op.drop_index('ix_file_size')
        batch_op.drop_column('size')
        batch_op.drop_column('datapath')
        batch_op.drop_column('jsonpath')

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('file', schema=None) as batch_op:
        batch_op.alter_column('meta', nullable=True, existing_type=sa.JSON(), new_column_name='json')
        batch_op.add_column(sa.Column('jsonpath', sa.TEXT(), nullable=True))
        batch_op.add_column(sa.Column('datapath', sa.TEXT(), nullable=True))
        batch_op.add_column(sa.Column('size', sa.INTEGER(), nullable=True))
        batch_op.create_index('ix_file_size', ['size'], unique=False)
        batch_op.create_index('ix_file_jsonpath', ['jsonpath'], unique=1)
        batch_op.create_index('ix_file_datapath', ['datapath'], unique=1)

    # data migration
    connection = op.get_bind()
    for file in connection.execute(filetable.select()):
        datapath = None
        jsonpath = None
        size = None
        for prod in connection.execute(producttable.select().where(producttable.c.file_id == file.id)):
            if prod.type == 'MAIN':
                datapath = prod.path
                size = prod.size
            elif prod.type == 'META':
                jsonpath = prod.path
        assert(datapath)
        assert(jsonpath)
        assert(size)
        connection.execute(filetable.update().where(filetable.c.id == file.id).values(datapath=datapath, jsonpath=jsonpath, size=size))

    with op.batch_alter_table('product', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_product_type'))
        batch_op.drop_index(batch_op.f('ix_product_size'))
        batch_op.drop_index(batch_op.f('ix_product_path'))

    op.drop_table('product')
    # ### end Alembic commands ###
